---
title: Vibe Coding Reproducability Challenge
nav: true
---

# Vibe Coding Reproducability Challenge

The advent of "Vibe Coding" has posed new risks and potential for reproducibility. On one hand, many developers feel like they can accomplish work faster, tackle larger projects, and be especially effective in "start from nothing" tasks. On the other hand, vibe coding has also entered the parlance of "AI slop" where outputs are derided for inaccuracies and over-engineered complexity. 

As such, we challenge the community to pick one of the three selected papers below to attempt reproductions using any LLMs they wish as assistive tools. Each document was selected based on a different property in the nature of both the paper's style, subject, and our knowledge about the paper's history and implementations available online. Please do not overly copy/port any online code, but attempt to implement the method ``from scratch'' using your preferred language and frameworks such as Python with Numpy/Pytorch/JAX, or even Rust if you so desire. For each of the three papers, we also include a best-effort OCR scan of the document to enable using more LLMs, but please feel free to use the original PDFs as desired. 

We ask authors to include a write-up with their results, code, and self-reflections on the experience. Our intent is to analyze the submissions and invite authors to join us in writing a collective study/result paper to be submitted at a yet-to-be-determined journal or conference. 

## Online Learning for Latent Dirichlet Allocation

Original paper: [here](https://papers.nips.cc/paper_files/paper/2010/hash/71f6278d140af599e06ad9bf1ba03cb0-Abstract.html) and [markdown version](https://raw.githubusercontent.com/ReproducibleAI/reproducibleai.github.io/refs/heads/main/onlineLDA.md)

## Deep Learning for Extreme Multi-label Text Classification

Original paper: [here](https://dl.acm.org/doi/10.1145/3077136.3080834) and [markdown version](https://raw.githubusercontent.com/ReproducibleAI/reproducibleai.github.io/refs/heads/main/xmlcnn.md)

## Breaking the linear iteration cost barrier for some well-known conditional gradient methods using MaxIP data-structures

Original paper: [here](https://proceedings.neurips.cc/paper/2021/file/2c27a260f16ad3098393cc529f391f4a-Paper.pdf) and [markdown version](https://raw.githubusercontent.com/ReproducibleAI/reproducibleai.github.io/refs/heads/main/lshMaxIP)
